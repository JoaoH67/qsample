# AUTOGENERATED! DO NOT EDIT! File to edit: 06_samplers.ipynb (unless otherwise specified).

__all__ = ['ONE_QUBIT_GATES', 'TWO_QUBIT_GATES', 'GATE_GROUPS', 'Sampler', 'DirectSampler', 'uniform_select',
           'ERV_select', 'calc_w_max', 'calc_partition_weight_vecs', 'calc_subset_occurances', 'calc_statistics',
           'SubsetSampler']

# Cell
import qsam.math as math
from .circuit import partition
from .simulators.chp import CHP
from .fault_generators import Depolar

import numpy as np
import itertools as it

# Cell
ONE_QUBIT_GATES = {'H', 'X', 'Z'}
TWO_QUBIT_GATES = {'CNOT'}

GATE_GROUPS = {'p': ONE_QUBIT_GATES | TWO_QUBIT_GATES,
               'p1': ONE_QUBIT_GATES,
               'p2': TWO_QUBIT_GATES }

# Cell
class Sampler:
    """Sampler base class"""

    def __init__(self, circuit, err_params):
        self.circuit = circuit
        self.n_qubits = circuit.n_qubits
        self.partitions = [partition(circuit, GATE_GROUPS[g]) for g in err_params.keys()]
        self.p_phys_mat = np.vstack(list(err_params.values())).T # p_phy_range x partitions
        self.fault_gen = Depolar(n_ticks=len(circuit))

    def _sample(self, params):
        sim = CHP(self.n_qubits)
        fault_circuit = self.fault_gen.generate(self.partitions, params, type(self).__name__)
        return sim.run(self.circuit, fault_circuit)

    def _check_logical_failure(self, msmt):
        return 1 if msmt.items() <= self.circuit.failures.items() else 0

# Cell
class DirectSampler(Sampler):
    """Direct Monte Carlo sampler"""

    def run(self, n_samples=100, var=math.Wilson_var):
        fail_cnts = np.zeros((self.p_phys_mat.shape[0])) # one fail counter per p_phys

        for i, p_phys in enumerate(self.p_phys_mat):
            for _ in range(n_samples):
                msmt = self._sample(p_phys)
                fail_cnts[i] += self._check_logical_failure(msmt)

        p_L = fail_cnts / n_samples
        std = np.sqrt( var(p_L, n_samples) )
        return p_L, std

# Cell
#export
def uniform_select(counts, *args, **kwargs):
    """Return index of least sampled SS"""
    return np.argmin(counts)

def ERV_select(counts, fail_counts, ss_factors=1, var=math.Wilson_var, *args, **kwargs):
    """Return index of SS which yields maximum ERV"""

    p = fail_counts / counts # list of SS failure rates
    v = var(p, counts) # list of variances

    # prospective failure rates
    p_p = (fail_counts+1) / (counts+1) # next msmt yields +1 (i.e. 1)
    p_m = fail_counts / (counts+1) # next msmt yields -1 (i.e. 0)

    # prospective variances
    v_p = var(p_p, counts+1)
    v_m = var(p_m, counts+1)

    # expectation value of prospective variances
    v_prop = p*v_p + (1-p)*v_m

    # maximize difference (scaled by occurance prob)
    delta = ss_factors**2 * (v - v_prop)
    return np.argmax(delta)

# Cell
#export
def calc_w_max(p_max, delta_max, n_partition_elems):
    """Calculate weight cutoff at p_max for delta_max."""

    delta = 1
    for w_max in range(n_partition_elems+1):
        delta -= math.binom(w_max, n_partition_elems, p_max)
        if delta < delta_max:
            break
    return w_max

# def calc_partition_weight_vecs(p_maxs, delta_maxs, partitions):
#     """Find w_max vector for delta_max at p_max and
#     return all partition weight vectors up to w_max_vec"""

#     assert len(p_maxs) == len(delta_maxs) == len(partitions)
#     w_max_vec = [calc_w_max(p_max,d_max,len(partition)) for p_max,d_max,partition in zip(p_maxs,delta_maxs,partitions)]
#     w_vecs = list(it.product( *[list(range(w_max+1)) for w_max in w_max_vec] ))
#     return w_vecs

def calc_partition_weight_vecs(p_max, delta_max, partitions):
    # Find w_max vector for delta_max at p_max
    assert len(p_max) == len(delta_max) == len(partitions)
    w_cutoff = np.zeros_like(p_max, dtype=int)
    for i in range(len(w_cutoff)):
        w_cutoff[i] = calc_w_max(p_max[i], delta_max[i], len(partitions[i]))
    # Generate weight vectors (combis of all ws up to each w_max per partition)
    w_vecs = list(it.product( *[list(range(w_cutoff_i+1)) for w_cutoff_i in w_cutoff] ))
    return w_vecs

def calc_subset_occurances(partitions, partition_weight_vecs, p_phys_mat):
    """Calculate 3D tensor of binom. coefficients for each partition"""

    n_partition_elems = np.array([len(p) for p in partitions])
    Aws = np.array([math.binom(w_vec, n_partition_elems, p_phys_mat) for w_vec in partition_weight_vecs])
    Aws = np.product(Aws, axis=-1) # get list of Aw for each partition SS combination
    return Aws

def calc_statistics(Aws, pws, n_samples, var=math.Wilson_var):
    """Calculate upper and lower bounds on logical failure rate and standard deviation"""

    p_L_low = np.sum(Aws * pws, axis=0)
    p_L_up = p_L_low + 1 - np.sum(Aws, axis=0)
    std = math.std_sum(Aws, pws, n_samples, var)
    return p_L_up, p_L_low, std

# Cell
class SubsetSampler(Sampler):
    """Monte Carlo subset sampler"""

    def __init__(self, circuit, err_params, subset_select_fn=uniform_select):
        self.subset_select_fn = subset_select_fn
        super().__init__(circuit, err_params)

    def _monte_carlo(self, w_vecs, n_samples):
        """Generate 1D list of subset failure rates per weight vector combi"""
        cnts      = np.zeros((len(w_vecs))) + 1 # one virtual sample to avoid div0
        fail_cnts = np.zeros((len(w_vecs)))

        for i in range(n_samples):
            idx = self.subset_select_fn(cnts, fail_cnts)
            w_vec = w_vecs[idx]
            msmt = self._sample(w_vec)
            fail_cnts[idx] += self._check_logical_failure(msmt)
            cnts[idx] += 1
        return fail_cnts, cnts - 1 # remove virtual sample

    def run(self, p_max, delta_max, n_samples=20, var=math.Wilson_var):

        w_vecs = calc_partition_weight_vecs(p_max, delta_max, self.partitions)
        fail_cnts, cnts = self._monte_carlo(w_vecs, n_samples)

        pws = (fail_cnts / cnts)[:,None]
        Aws = calc_subset_occurances(self.partitions, w_vecs, self.p_phys_mat) # TODO: ERV, GIVE LARGEST Aw.

        return calc_statistics(Aws, pws, n_samples, var)